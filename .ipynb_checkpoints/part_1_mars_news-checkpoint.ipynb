{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 Challenge\n",
    "## Deliverable 1: Scrape Titles and Preview Text from Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "DriverNotFoundError",
     "evalue": "Driver for chrome was not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDriverNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m browser \u001b[38;5;241m=\u001b[39m Browser(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchrome\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/splinter/browser.py:128\u001b[0m, in \u001b[0;36mBrowser\u001b[0;34m(driver_name, retry_count, config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DriverNotFoundError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdriver_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a recognized driver.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m driver \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DriverNotFoundError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDriver for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdriver_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_driver(driver, retry_count\u001b[38;5;241m=\u001b[39mretry_count, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mDriverNotFoundError\u001b[0m: Driver for chrome was not found."
     ]
    }
   ],
   "source": [
    "browser = Browser('chrome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Visit the Website\n",
    "\n",
    "1. Use automated browsing to visit the [Mars news site](https://static.bc-edx.com/data/web/mars_news/index.html). Inspect the page to identify which elements to scrape.\n",
    "\n",
    "      > **Hint** To identify which elements to scrape, you might want to inspect the page by using Chrome DevTools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'browser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visit the Mars news site\u001b[39;00m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://static.bc-edx.com/data/web/mars_news/index.html\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m browser\u001b[38;5;241m.\u001b[39mvisit(url)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'browser' is not defined"
     ]
    }
   ],
   "source": [
    "# Visit the Mars news site\n",
    "url = 'https://static.bc-edx.com/data/web/mars_news/index.html'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the Website\n",
    "\n",
    "Create a Beautiful Soup object and use it to extract text elements from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'browser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m html \u001b[38;5;241m=\u001b[39m browser\u001b[38;5;241m.\u001b[39mhtml\n",
      "\u001b[0;31mNameError\u001b[0m: name 'browser' is not defined"
     ]
    }
   ],
   "source": [
    "html = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'html' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a Beautiful Soup object\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(html, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'html' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a Beautiful Soup object\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text_box \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mselect_one(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv.list_text\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "text_box = soup.select_one('div.list_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract all the text elements\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# # Save the main area of the web page to a variable\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     main_area = soup.find(\"div\", class_=\"post-archive-container\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     # Find all the articles in the main area of the web page\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m articles \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlist_text\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract all the text elements\n",
    "# # Save the main area of the web page to a variable\n",
    "#     main_area = soup.find(\"div\", class_=\"post-archive-container\")\n",
    "    \n",
    "#     # Find all the articles in the main area of the web page\n",
    "articles = soup.find_all(\"div\", class_=\"list_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1815379337.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    html = browser.html\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Create a function to perform the web scraping\n",
    "# def get_summary():\n",
    "    # Collect the HTML from the browser\n",
    "    html = browser.html\n",
    "    # Parse the HTML with Beautiful Soup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    # Create an empty list to hold summaries\n",
    "    summary_list = []\n",
    "\n",
    "        # Loop through the articles\n",
    "    for article in articles:\n",
    "            # Collect the article title\n",
    "        header = article.find(\"div\", class_=\"content_title\").text.strip()\n",
    "            # Collect the article date\n",
    "        teaser = article.find(\"div\", class_=\"article_teaser_body\").text.strip()\n",
    "\n",
    "            # Create the summary dictionary\n",
    "        summary_dict = {\n",
    "            \"title\": header,\n",
    "            \"preview\": teaser\n",
    "        }\n",
    "            # Append the summary dictionary to the list\n",
    "        summary_list.append(summary_dict)\n",
    "\n",
    "        # Return the list of summaries\n",
    "return summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;66;03m# Loop through the articles\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m articles:\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;66;03m# Collect the article title\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         header \u001b[38;5;241m=\u001b[39m article\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_title\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      7\u001b[0m             \u001b[38;5;66;03m# Collect the article date\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'articles' is not defined"
     ]
    }
   ],
   "source": [
    "summary_list = []\n",
    "\n",
    "        # Loop through the articles\n",
    "for article in articles:\n",
    "            # Collect the article title\n",
    "        header = article.find(\"div\", class_=\"content_title\").text.strip()\n",
    "            # Collect the article date\n",
    "        teaser = article.find(\"div\", class_=\"article_teaser_body\").text.strip()\n",
    "\n",
    "            # Create the summary dictionary\n",
    "        summary_dict = {\n",
    "            \"title\": header,\n",
    "            \"preview\": teaser\n",
    "        }\n",
    "            # Append the summary dictionary to the list\n",
    "        summary_list.append(summary_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store the Results\n",
    "\n",
    "Extract the titles and preview text of the news articles that you scraped. Store the scraping results in Python data structures as follows:\n",
    "\n",
    "* Store each title-and-preview pair in a Python dictionary. And, give each dictionary two keys: `title` and `preview`. An example is the following:\n",
    "\n",
    "  ```python\n",
    "  {'title': \"NASA's MAVEN Observes Martian Light Show Caused by Major Solar Storm\", \n",
    "   'preview': \"For the first time in its eight years orbiting Mars, NASA’s MAVEN mission witnessed two different types of ultraviolet aurorae simultaneously, the result of solar storms that began on Aug. 27.\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "* Store all the dictionaries in a Python list.\n",
    "\n",
    "* Print the list in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the text elements\n",
    "# Extract the title and preview text from the elements\n",
    "# Store each title and preview pair in a dictionary\n",
    "# Add the dictionary to the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list to confirm success\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
